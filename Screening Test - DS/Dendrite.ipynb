{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81e1fc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries and modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0953d27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width      species\n",
       "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
       "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
       "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
       "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
       "4           5.0          3.6           1.4          0.2  Iris-setosa\n",
       "5           5.4          3.9           1.7          0.4  Iris-setosa\n",
       "6           4.6          3.4           1.4          0.3  Iris-setosa\n",
       "7           5.0          3.4           1.5          0.2  Iris-setosa\n",
       "8           4.4          2.9           1.4          0.2  Iris-setosa\n",
       "9           4.9          3.1           1.5          0.1  Iris-setosa"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading the dataset\n",
    "df = pd.read_csv(\"iris.csv\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5be668c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(df.isna().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e33aba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify columns with missing values and the appropriate imputation technique\n",
    "imputation_dict = {\n",
    "    'sepal_length': 'mean',  # impute with mean\n",
    "    'sepal_width': 'mean',  # impute with mean\n",
    "    'petal_length': 'mean',  # impute with mean\n",
    "    'petal_width': 'mean',  # impute with mean\n",
    "    'species': 'ffill',  # impute with forward fill\n",
    "}\n",
    "\n",
    "# Apply imputation to each column with missing values\n",
    "for col, imputation in imputation_dict.items():\n",
    "    if df[col].isnull().sum() > 0:  # check if column has missing values\n",
    "        if imputation == 'mean':\n",
    "            df[col].fillna(df[col].mode()[0], inplace=True)\n",
    "        elif imputation == 'ffill':\n",
    "            df[col].fillna(method='ffill', inplace=True)\n",
    "\n",
    "# Save the imputed DataFrame to a new CSV file\n",
    "df.to_csv('imputed_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5ca102",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "816f3212",
   "metadata": {},
   "source": [
    "### The code should be able to handle both numerical and categorical features, impute the missing values using appropriate methods depending on the feature type.and  handle the outliers by replacing them with either the mean or the median of the respective feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0700b937",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "def impute_missing_values_and_handle_outliers(data):\n",
    "    # Copy the input data to avoid modifying the original data\n",
    "    data_imputed = data.copy()\n",
    "\n",
    "    # Define a list of numerical features\n",
    "    numerical_features = list(data.select_dtypes(include=[np.number]).columns)\n",
    "\n",
    "    # Define a list of categorical features\n",
    "    categorical_features = list(data.select_dtypes(exclude=[np.number]).columns)\n",
    "\n",
    "    # Impute missing values in numerical features with the median\n",
    "    data_imputed[numerical_features] = data_imputed[numerical_features].fillna(data_imputed[numerical_features].median())\n",
    "\n",
    "    # Impute missing values in categorical features with the mode\n",
    "    data_imputed[categorical_features] = data_imputed[categorical_features].fillna(data_imputed[categorical_features].mode().iloc[0])\n",
    "\n",
    "    # Handle outliers in numerical features with the Z-score method\n",
    "    for feature in numerical_features:\n",
    "        z_scores = np.abs(stats.zscore(data_imputed[feature]))\n",
    "        threshold = 3\n",
    "        outliers = data_imputed[z_scores > threshold][feature]\n",
    "        if outliers.shape[0] > 0:\n",
    "            data_imputed.loc[z_scores > threshold, feature] = data_imputed[feature].median()\n",
    "\n",
    "    return data_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b877df8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'session_name': 'test',\n",
       " 'session_description': 'test',\n",
       " 'design_state_data': {'session_info': {'project_id': '1',\n",
       "   'experiment_id': 'kkkk-11',\n",
       "   'dataset': 'iris_modified.csv',\n",
       "   'session_name': 'test',\n",
       "   'session_description': 'test'},\n",
       "  'target': {'prediction_type': 'Regression',\n",
       "   'target': 'petal_width',\n",
       "   'type': 'regression',\n",
       "   'partitioning': True},\n",
       "  'train': {'policy': 'Split the dataset',\n",
       "   'time_variable': 'sepal_length',\n",
       "   'sampling_method': 'No sampling(whole data)',\n",
       "   'split': 'Randomly',\n",
       "   'k_fold': False,\n",
       "   'train_ratio': 0,\n",
       "   'random_seed': 0},\n",
       "  'metrics': {'optomize_model_hyperparameters_for': 'AUC',\n",
       "   'optimize_threshold_for': 'F1 Score',\n",
       "   'compute_lift_at': 0,\n",
       "   'cost_matrix_gain_for_true_prediction_true_result': 1,\n",
       "   'cost_matrix_gain_for_true_prediction_false_result': 0,\n",
       "   'cost_matrix_gain_for_false_prediction_true_result': 0,\n",
       "   'cost_matrix_gain_for_false_prediction_false_result': 0},\n",
       "  'feature_handling': {'sepal_length': {'feature_name': 'sepal_length',\n",
       "    'is_selected': True,\n",
       "    'feature_variable_type': 'numerical',\n",
       "    'feature_details': {'numerical_handling': 'Keep as regular numerical feature',\n",
       "     'rescaling': 'No rescaling',\n",
       "     'make_derived_feats': False,\n",
       "     'missing_values': 'Impute',\n",
       "     'impute_with': 'Average of values',\n",
       "     'impute_value': 0}},\n",
       "   'sepal_width': {'feature_name': 'sepal_width',\n",
       "    'is_selected': True,\n",
       "    'feature_variable_type': 'numerical',\n",
       "    'feature_details': {'numerical_handling': 'Keep as regular numerical feature',\n",
       "     'rescaling': 'No rescaling',\n",
       "     'make_derived_feats': False,\n",
       "     'missing_values': 'Impute',\n",
       "     'impute_with': 'custom',\n",
       "     'impute_value': -1}},\n",
       "   'petal_length': {'feature_name': 'petal_length',\n",
       "    'is_selected': True,\n",
       "    'feature_variable_type': 'numerical',\n",
       "    'feature_details': {'numerical_handling': 'Keep as regular numerical feature',\n",
       "     'rescaling': 'No rescaling',\n",
       "     'make_derived_feats': False,\n",
       "     'missing_values': 'Impute',\n",
       "     'impute_with': 'Average of values',\n",
       "     'impute_value': 0}},\n",
       "   'petal_width': {'feature_name': 'petal_width',\n",
       "    'is_selected': True,\n",
       "    'feature_variable_type': 'numerical',\n",
       "    'feature_details': {'numerical_handling': 'Keep as regular numerical feature',\n",
       "     'rescaling': 'No rescaling',\n",
       "     'make_derived_feats': False,\n",
       "     'missing_values': 'Impute',\n",
       "     'impute_with': 'custom',\n",
       "     'impute_value': -2}},\n",
       "   'species': {'feature_name': 'species',\n",
       "    'is_selected': True,\n",
       "    'feature_variable_type': 'text',\n",
       "    'feature_details': {'text_handling': 'Tokenize and hash',\n",
       "     'hash_columns': 0}}},\n",
       "  'feature_generation': {'linear_interactions': [['petal_length',\n",
       "     'sepal_width']],\n",
       "   'linear_scalar_type': 'robust',\n",
       "   'polynomial_interactions': ['petal_length/sepal_width',\n",
       "    'petal_width/species'],\n",
       "   'explicit_pairwise_interactions': ['sepal_width/sepal_length',\n",
       "    'petal_width/sepal_length']},\n",
       "  'feature_reduction': {'feature_reduction_method': 'Tree-based',\n",
       "   'num_of_features_to_keep': '4',\n",
       "   'num_of_trees': '5',\n",
       "   'depth_of_trees': '6'},\n",
       "  'hyperparameters': {'stratergy': 'Grid Search',\n",
       "   'shuffle_grid': True,\n",
       "   'random_state': 1,\n",
       "   'max_iterations': 2,\n",
       "   'max_search_time': 3,\n",
       "   'parallelism': 5,\n",
       "   'cross_validation_stratergy': 'Time-based K-fold(with overlap)',\n",
       "   'num_of_folds': 6,\n",
       "   'split_ratio': 0,\n",
       "   'stratified': True},\n",
       "  'weighting_stratergy': {'weighting_stratergy_method': 'Sample weights',\n",
       "   'weighting_stratergy_weight_variable': 'petal_length'},\n",
       "  'probability_calibration': {'probability_calibration_method': 'Sigmoid - Platt Scaling'},\n",
       "  'algorithms': {'RandomForestClassifier': {'model_name': 'Random Forest Classifier',\n",
       "    'is_selected': False,\n",
       "    'min_trees': 10,\n",
       "    'max_trees': 30,\n",
       "    'feature_sampling_statergy': 'Default',\n",
       "    'min_depth': 20,\n",
       "    'max_depth': 30,\n",
       "    'min_samples_per_leaf_min_value': 5,\n",
       "    'min_samples_per_leaf_max_value': 50,\n",
       "    'parallelism': 0},\n",
       "   'RandomForestRegressor': {'model_name': 'Random Forest Regressor',\n",
       "    'is_selected': True,\n",
       "    'min_trees': 10,\n",
       "    'max_trees': 20,\n",
       "    'feature_sampling_statergy': 'Default',\n",
       "    'min_depth': 20,\n",
       "    'max_depth': 25,\n",
       "    'min_samples_per_leaf_min_value': 5,\n",
       "    'min_samples_per_leaf_max_value': 10,\n",
       "    'parallelism': 0},\n",
       "   'GBTClassifier': {'model_name': 'Gradient Boosted Trees',\n",
       "    'is_selected': False,\n",
       "    'num_of_BoostingStages': [67, 89],\n",
       "    'feature_sampling_statergy': 'Fixed number',\n",
       "    'learningRate': [],\n",
       "    'use_deviance': True,\n",
       "    'use_exponential': False,\n",
       "    'fixed_number': 22,\n",
       "    'min_subsample': 1,\n",
       "    'max_subsample': 2,\n",
       "    'min_stepsize': 0.1,\n",
       "    'max_stepsize': 0.5,\n",
       "    'min_iter': 20,\n",
       "    'max_iter': 40,\n",
       "    'min_depth': 5,\n",
       "    'max_depth': 7},\n",
       "   'GBTRegressor': {'model_name': 'Gradient Boosted Trees',\n",
       "    'is_selected': False,\n",
       "    'num_of_BoostingStages': [67, 89],\n",
       "    'feature_sampling_statergy': 'Fixed number',\n",
       "    'use_deviance': True,\n",
       "    'use_exponential': False,\n",
       "    'fixed_number': 22,\n",
       "    'min_subsample': 1,\n",
       "    'max_subsample': 2,\n",
       "    'min_stepsize': 0.1,\n",
       "    'max_stepsize': 0.5,\n",
       "    'min_iter': 20,\n",
       "    'max_iter': 40,\n",
       "    'min_depth': 5,\n",
       "    'max_depth': 7},\n",
       "   'LinearRegression': {'model_name': 'LinearRegression',\n",
       "    'is_selected': False,\n",
       "    'parallelism': 2,\n",
       "    'min_iter': 30,\n",
       "    'max_iter': 50,\n",
       "    'min_regparam': 0.5,\n",
       "    'max_regparam': 0.8,\n",
       "    'min_elasticnet': 0.5,\n",
       "    'max_elasticnet': 0.8},\n",
       "   'LogisticRegression': {'model_name': 'LogisticRegression',\n",
       "    'is_selected': False,\n",
       "    'parallelism': 2,\n",
       "    'min_iter': 30,\n",
       "    'max_iter': 50,\n",
       "    'min_regparam': 0.5,\n",
       "    'max_regparam': 0.8,\n",
       "    'min_elasticnet': 0.5,\n",
       "    'max_elasticnet': 0.8},\n",
       "   'RidgeRegression': {'model_name': 'RidgeRegression',\n",
       "    'is_selected': False,\n",
       "    'regularization_term': 'Specify values to test',\n",
       "    'min_iter': 30,\n",
       "    'max_iter': 50,\n",
       "    'min_regparam': 0.5,\n",
       "    'max_regparam': 0.8},\n",
       "   'LassoRegression': {'model_name': 'Lasso Regression',\n",
       "    'is_selected': False,\n",
       "    'regularization_term': 'Specify values to test',\n",
       "    'min_iter': 30,\n",
       "    'max_iter': 50,\n",
       "    'min_regparam': 0.5,\n",
       "    'max_regparam': 0.8},\n",
       "   'ElasticNetRegression': {'model_name': 'Lasso Regression',\n",
       "    'is_selected': False,\n",
       "    'regularization_term': 'Specify values to test',\n",
       "    'min_iter': 30,\n",
       "    'max_iter': 50,\n",
       "    'min_regparam': 0.5,\n",
       "    'max_regparam': 0.8,\n",
       "    'min_elasticnet': 0.5,\n",
       "    'max_elasticnet': 0.8},\n",
       "   'xg_boost': {'model_name': 'XG Boost',\n",
       "    'is_selected': False,\n",
       "    'use_gradient_boosted_tree': True,\n",
       "    'dart': True,\n",
       "    'tree_method': '',\n",
       "    'random_state': 0,\n",
       "    'max_num_of_trees': 0,\n",
       "    'early_stopping': True,\n",
       "    'early_stopping_rounds': 2,\n",
       "    'max_depth_of_tree': [56, 89],\n",
       "    'learningRate': [89, 76],\n",
       "    'l1_regularization': [77],\n",
       "    'l2_regularization': [78],\n",
       "    'gamma': [68],\n",
       "    'min_child_weight': [67],\n",
       "    'sub_sample': [67],\n",
       "    'col_sample_by_tree': [67],\n",
       "    'replace_missing_values': False,\n",
       "    'parallelism': 0},\n",
       "   'DecisionTreeRegressor': {'model_name': 'Decision Tree',\n",
       "    'is_selected': False,\n",
       "    'min_depth': 4,\n",
       "    'max_depth': 7,\n",
       "    'use_gini': False,\n",
       "    'use_entropy': True,\n",
       "    'min_samples_per_leaf': [12, 6],\n",
       "    'use_best': True,\n",
       "    'use_random': True},\n",
       "   'DecisionTreeClassifier': {'model_name': 'Decision Tree',\n",
       "    'is_selected': False,\n",
       "    'min_depth': 4,\n",
       "    'max_depth': 7,\n",
       "    'use_gini': False,\n",
       "    'use_entropy': True,\n",
       "    'min_samples_per_leaf': [12, 6],\n",
       "    'use_best': True,\n",
       "    'use_random': True},\n",
       "   'SVM': {'model_name': 'Support Vector Machine',\n",
       "    'is_selected': False,\n",
       "    'linear_kernel': True,\n",
       "    'rep_kernel': True,\n",
       "    'polynomial_kernel': True,\n",
       "    'sigmoid_kernel': True,\n",
       "    'c_value': [566, 79],\n",
       "    'auto': True,\n",
       "    'scale': True,\n",
       "    'custom_gamma_values': True,\n",
       "    'tolerance': 7,\n",
       "    'max_iterations': 7},\n",
       "   'SGD': {'model_name': 'Stochastic Gradient Descent',\n",
       "    'is_selected': False,\n",
       "    'use_logistics': True,\n",
       "    'use_modified_hubber_loss': False,\n",
       "    'max_iterations': False,\n",
       "    'tolerance': 56,\n",
       "    'use_l1_regularization': 'on',\n",
       "    'use_l2_regularization': 'on',\n",
       "    'use_elastic_net_regularization': True,\n",
       "    'alpha_value': [79, 56],\n",
       "    'parallelism': 1},\n",
       "   'KNN': {'model_name': 'KNN',\n",
       "    'is_selected': False,\n",
       "    'k_value': [78],\n",
       "    'distance_weighting': True,\n",
       "    'neighbour_finding_algorithm': 'Automatic',\n",
       "    'random_state': 0,\n",
       "    'p_value': 0},\n",
       "   'extra_random_trees': {'model_name': 'Extra Random Trees',\n",
       "    'is_selected': False,\n",
       "    'num_of_trees': [45, 489],\n",
       "    'feature_sampling_statergy': 'Square root and Logarithm',\n",
       "    'max_depth': [12, 45],\n",
       "    'min_samples_per_leaf': [78, 56],\n",
       "    'parallelism': 3},\n",
       "   'neural_network': {'model_name': 'Neural Network',\n",
       "    'is_selected': False,\n",
       "    'hidden_layer_sizes': [67, 89],\n",
       "    'activation': '',\n",
       "    'alpha_value': 0,\n",
       "    'max_iterations': 0,\n",
       "    'convergence_tolerance': 0,\n",
       "    'early_stopping': True,\n",
       "    'solver': 'ADAM',\n",
       "    'shuffle_data': True,\n",
       "    'initial_learning_rate': 0,\n",
       "    'automatic_batching': True,\n",
       "    'beta_1': 0,\n",
       "    'beta_2': 0,\n",
       "    'epsilon': 0,\n",
       "    'power_t': 0,\n",
       "    'momentum': 0,\n",
       "    'use_nesterov_momentum': False}}}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e385b50",
   "metadata": {},
   "source": [
    "### This code is flexible enough to work with different user input by simply changing the value of the \"method\" key in the input JSON file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c8d4557",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, SelectFromModel\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "with open('Algoparams.json', 'r') as f:\n",
    "    input_data = json.load(f)\n",
    "\n",
    "# Load the dataset from a CSV file\n",
    "df = pd.read_csv('iris.csv')\n",
    "\n",
    "# Perform feature reduction based on user input\n",
    "if input_data['session_name'] == 'test':\n",
    "    pass  # Do nothing\n",
    "elif input_data['session_name'] == 'Corr with Target':\n",
    "    X = df.drop(input_data['target_column'], axis=1)\n",
    "    y = df[input_data['target_column']]\n",
    "    k = input_data['k']\n",
    "    skb = SelectKBest(f_regression, k=k)\n",
    "    X_new = skb.fit_transform(X, y)\n",
    "    df = pd.concat([pd.DataFrame(X_new), y], axis=1)\n",
    "elif input_data['method'] == 'Tree-based':\n",
    "    X = df.drop(input_data['target_column'], axis=1)\n",
    "    y = df[input_data['target_column']]\n",
    "    clf = ExtraTreesRegressor(n_estimators=50)\n",
    "    clf = clf.fit(X, y)\n",
    "    sfm = SelectFromModel(clf, prefit=True)\n",
    "    X_new = sfm.transform(X)\n",
    "    df = pd.concat([pd.DataFrame(X_new), y], axis=1)\n",
    "elif input_data['method'] == 'PCA':\n",
    "    X = df.drop(input_data['target_column'], axis=1)\n",
    "    y = df[input_data['target_column']]\n",
    "    n_components = input_data['n_components']\n",
    "    pca = PCA(n_components=n_components)\n",
    "    X_new = pca.fit_transform(X)\n",
    "    df = pd.concat([pd.DataFrame(X_new), y], axis=1)\n",
    "\n",
    "# Save the resulting dataset to a CSV file\n",
    "df.to_csv('result.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b75ba27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "283a1d9e",
   "metadata": {},
   "source": [
    "### After creating the model object, we can train the model on the data and make predictions using the appropriate methods for the chosen model object. If the prediction type or model type specified in the input JSON is not valid, a ValueError is raised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b386e15e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'prediction_type'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [21]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Create the appropriate model object based on the prediction type\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m input_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msession_description\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m---> 11\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43minput_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprediction_type\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRegression\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     12\u001b[0m         model \u001b[38;5;241m=\u001b[39m LinearRegression()\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m input_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprediction_type\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDecisionTreeRegressor\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "\u001b[1;31mKeyError\u001b[0m: 'prediction_type'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "\n",
    "# Load the input data from a JSON file\n",
    "with open('Algoparams.json', 'r') as f:\n",
    "    input_data = json.load(f)\n",
    "\n",
    "# Create the appropriate model object based on the prediction type\n",
    "if input_data['session_description'] == 'test':\n",
    "    if input_data['prediction_type'] == 'Regression':\n",
    "        model = LinearRegression()\n",
    "    elif input_data['prediction_type'] == 'DecisionTreeRegressor':\n",
    "        model = DecisionTreeRegressor()\n",
    "    else:\n",
    "        raise ValueError('Invalid model type for regression')\n",
    "elif input_data['prediction_type'] == 'Classification':\n",
    "    if input_data['prediction_type'] == 'LogisticRegression':\n",
    "        model = LogisticRegression()\n",
    "    elif input_data['prediction_type'] == 'DecisionTreeClassifier':\n",
    "        model = DecisionTreeClassifier()\n",
    "    else:\n",
    "        raise ValueError('Invalid model type for classification')\n",
    "else:\n",
    "    raise ValueError('Invalid prediction type')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7530e91f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a53bdc4",
   "metadata": {},
   "source": [
    "### Code to import data, take in inputs and use GridSearch CV to train model based on selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e52ba818",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'X_train'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [25]\u001b[0m, in \u001b[0;36m<cell line: 15>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m     input_data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Extract the relevant data from the input\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m X_train \u001b[38;5;241m=\u001b[39m \u001b[43minput_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mX_train\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     16\u001b[0m y_train \u001b[38;5;241m=\u001b[39m input_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_train\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     17\u001b[0m X_test \u001b[38;5;241m=\u001b[39m input_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX_test\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mKeyError\u001b[0m: 'X_train'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Load the input data from a JSON file\n",
    "with open('Algoparams.json', 'r') as f:\n",
    "    input_data = json.load(f)\n",
    "\n",
    "# Extract the relevant data from the input\n",
    "X_train = input_data['X_train']\n",
    "y_train = input_data['y_train']\n",
    "X_test = input_data['X_test']\n",
    "\n",
    "# Define a dictionary of hyperparameters for each model\n",
    "param_grid = {\n",
    "    'linear_regression': {'normalize': [True, False]},\n",
    "    'decision_tree': {'max_depth': [2, 4, 6, 8, 10]},\n",
    "    'random_forest': {'n_estimators': [50, 100, 200, 500], 'max_depth': [2, 4, 6, 8, 10]},\n",
    "    'svm': {'C': [0.1, 1, 10, 100], 'gamma': [0.1, 1, 10, 100]},\n",
    "    'pca_lr': {'pca__n_components': [2, 4, 6, 8, 10], 'lr__normalize': [True, False]},\n",
    "    'pca_dt': {'pca__n_components': [2, 4, 6, 8, 10], 'dt__max_depth': [2, 4, 6, 8, 10]},\n",
    "    'pca_rf': {'pca__n_components': [2, 4, 6, 8, 10], 'rf__n_estimators': [50, 100, 200, 500], 'rf__max_depth': [2, 4, 6, 8, 10]}\n",
    "}\n",
    "\n",
    "# Define the pipelines for each model\n",
    "pipelines = {\n",
    "    'linear_regression': Pipeline([('lr', LinearRegression())]),\n",
    "    'decision_tree': Pipeline([('dt', DecisionTreeRegressor())]),\n",
    "    'random_forest': Pipeline([('rf', RandomForestRegressor())]),\n",
    "    'svm': Pipeline([('svm', SVR())]),\n",
    "    'pca_lr': Pipeline([('pca', PCA()), ('lr', LinearRegression())]),\n",
    "    'pca_dt': Pipeline([('pca', PCA()), ('dt', DecisionTreeRegressor())]),\n",
    "    'pca_rf': Pipeline([('pca', PCA()), ('rf', RandomForestRegressor())])\n",
    "}\n",
    "\n",
    "# Define the names of the models to train based on the input method chosen\n",
    "if input_data['prediction_type'] == 'No Reduction':\n",
    "    models = ['linear_regression', 'decision_tree', 'random_forest', 'svm']\n",
    "elif input_data['prediction_type'] == 'Corr with Target':\n",
    "    models = ['linear_regression', 'decision_tree', 'random_forest']\n",
    "elif input_data['prediction_type'] == 'Tree-based':\n",
    "    models = ['decision_tree', 'random_forest']\n",
    "elif input_data['prediction_type'] == 'PCA':\n",
    "    models = ['pca_lr', 'pca_dt', 'pca_rf']\n",
    "else:\n",
    "    print('Invalid prediction type specified')\n",
    "\n",
    "# Train the models using GridSearchCV\n",
    "for model_name in models:\n",
    "    print(f'Training {model_name}...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc04d7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1998fdce",
   "metadata": {},
   "source": [
    "### This will print out the classification report and confusion matrix in the console, which includes standard model metrics such as precision, recall, F1-score, and accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1d35eaae",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [26]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m classification_report, confusion_matrix\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# train and test the model\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m      5\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# log the classification report and confusion matrix\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# train and test the model\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# log the classification report and confusion matrix\n",
    "print('Classification Report:\\n', classification_report(y_test, y_pred))\n",
    "print('Confusion Matrix:\\n', confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc03a82f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9328e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a365b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63852c75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fee0f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7748e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b03a41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66fdfcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e62decb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14173e1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633f0f06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d595412",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2154a8f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c84161",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0603a52d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1a8d25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a8f078",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ccece7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb875f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184db7a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b41c94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a177c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39210495",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1398015",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53d2e4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252dfad4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e715831",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d50054b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c17d8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93e6447",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acda0cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03efcd24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcb05e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db012c09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137ced0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533d56dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffd448d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd46cb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375ad6d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e576f5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdffde7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c0dc72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24418c44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87a72ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d95eb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cff4e2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2490d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6ccfe8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b982e21a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a32b623",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721859b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00e9045",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3deccd60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be94cfd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78f4030",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bc10d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a04bf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ce6618",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a67073",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f56caa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182ca1bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab814bd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bc8a82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c19ac5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255ac05c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d97c204",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7600e473",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d855a4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdb800c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f8097c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adff84f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e4752b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab759da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7bb704",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5dc06f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d850ac99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6491232",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223b12f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961d68b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc56f6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5e1a82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11dd0271",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb563ca5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aec43ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb36e37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4306d81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556de860",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456956a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35d4cc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
